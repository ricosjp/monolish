#!/bin/bash
echo "//this code is generated by gen_tensor_crs_vml.sh
#pragma once

#include \"../common/monolish_common.hpp\"

namespace monolish {
/**
 * @brief
 * Vector and Matrix element-wise math library
 */
namespace vml {
"
echo "
/**
 * @addtogroup tensor_CRS_VML
 * @{
 */
"

## tensor_CRS matrix-matrix arithmetic
detail=(addition subtract multiplication division)
func=(add sub mul div)
for i in ${!detail[@]}; do
echo "
/**
 * \defgroup vml_crs${func[$i]} monolish::vml::${func[$i]}
 * @brief element by element ${detail[$i]} tensor_CRS matrix A and tensor_CRS matrix B.
 * @{
 */
/**
 * @brief element by element ${detail[$i]} tensor_CRS matrix A and
 * tensor_CRS matrix B.
 * @param A monolish tensor_CRS Matrix (size M x N)
 * @param B monolish tensor_CRS Matrix (size M x N)
 * @param C monolish tensor_CRS Matrix (size M x N)
 * @note
 * - # of computation: nnz
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 * @warning
 * A, B, and C must be same non-zero structure
*/ "
for prec in double float; do
  echo "void ${func[$i]}(const tensor::tensor_CRS<$prec> &A, const tensor::tensor_CRS<$prec> &B, tensor::tensor_CRS<$prec> &C);"
done
echo "/**@}*/"
done

echo ""
################################################################

## tensor_CRS matrix-scalar arithmetic
detail=(addition subtract multiplication division)
func=(add sub mul div)
for i in ${!detail[@]}; do
echo "
/**
 * \defgroup vml_scrs${func[$i]} monolish::vml::${func[$i]}
 * @brief element by element ${detail[$i]} scalar alpha and tensor_CRS matrix A.
 * @{
 */
/**
 * @brief element by element ${detail[$i]} scalar alpha and tensor_CRS matrix A.
 * @param A monolish tensor_CRS Matrix (size M x N)
 * @param alpha scalar value
 * @param C monolish tensor_CRS Matrix (size M x N)
 * @note
 * - # of computation: nnz
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 * @warning
 * A, B, and C must be same non-zero structure
*/ "
for prec in double float; do
  echo "void ${func[$i]}(const tensor::tensor_CRS<$prec> &A, const $prec alpha, tensor::tensor_CRS<$prec> &C);"
done
echo "/**@}*/"
done

echo ""
#############################################

## matrix-matrix pow
echo "
/**
 * \defgroup vml_crspow monolish::vml::pow
 * @brief power to tensor_CRS matrix elements (C[0:N] = pow(A[0:N], B[0:N]))
 * @{
 */
/**
 *@brief power to tensor_CRS matrix elements (C[0:N] = pow(A[0:N], B[0:N]))
 * @param A monolish tensor_CRS Matrix (size M x N)
 * @param B monolish tensor_CRS Matrix (size M x N)
 * @param C monolish tensor_CRS Matrix (size M x N)
 * @note
 * - # of computation: nnz
 * - Multi-threading: true
 * - GPU acceleration: true
 * @warning
 * A, B, and C must be same non-zero structure
*/ "
for prec in double float; do
  echo "void pow(const tensor::tensor_CRS<$prec> &A, const tensor::tensor_CRS<$prec> &B, tensor::tensor_CRS<$prec> &C);"
done
echo "/**@}*/"
 
echo "
/**
 * \defgroup vml_scrspow monolish::vml::pow
 * @brief power to tensor_CRS matrix elements by scalar value (C[0:N] = pow(A[0:N], alpha))
 * @{
 */
/**
 * @brief power to tensor_CRS matrix elements by scalar value (C[0:N] = pow(A[0:N], alpha))
 * @param A monolish tensor_CRS Matrix (size M x N)
 * @param alpha scalar value
 * @param C monolish tensor_CRS Matrix (size M x N)
 * @note
 * - # of computation: nnz
 * - Multi-threading: true
 * - GPU acceleration: true
 * @warning
 * A, B, and C must be same non-zero structure
*/ "
for prec in double float; do
  echo "void pow(const tensor::tensor_CRS<$prec> &A, const $prec alpha, tensor::tensor_CRS<$prec> &C);"
done
echo "/**@}*/"

echo ""
#############################################
## 2arg math
math=(sin sqrt sinh asin asinh tan tanh atan atanh ceil floor sign)
for math in ${math[@]}; do
echo "
/**
 * \defgroup vml_crs$math monolish::vml::$math
 * @brief $math to tensor_CRS matrix elements (C[0:nnz] = $math(A[0:nnz]))
 * @{
 */
/**
 * @brief $math to tensor_CRS matrix elements (C[0:nnz] = $math(A[0:nnz]))
 * @param A monolish tensor_CRS matrix (size M x N)
 * @param C monolish tensor_CRS matrix (size M x N)
 * @note
 * - # of computation: nnz
 * - Multi-threading: true
 * - GPU acceleration: true
 * @warning
 * A, B, and C must be same non-zero structure
*/ "
for prec in double float; do
  echo "void $math(const tensor::tensor_CRS<$prec> &A, tensor::tensor_CRS<$prec> &C);"
done
echo "/**@}*/"
done

echo ""
#############################################

## matrix-matrix max min
detail=(greatest smallest)
func=(max min)
for i in ${!detail[@]}; do
echo "
/**
 * \defgroup vml_crscrs${func[$i]} monolish::vml::${func[$i]}
 * @brief Create a new tensor_CRS matrix with ${detail[$i]} elements of two matrices (C[0:nnz] = ${func[$i]}(A[0:nnz], B[0:nnz]))
 * @{
 */
/**
 * @brief Create a new tensor_CRS matrix with ${detail[$i]} elements of two matrices (C[0:nnz] = ${func[$i]}(A[0:nnz], B[0:nnz]))
 * @param A monolish tensor_CRS matrix (size M x N)
 * @param B monolish tensor_CRS matrix (size M x N)
 * @param C monolish tensor_CRS matrix (size M x N)
 * @note
 * - # of computation: nnz
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 * @warning
 * A, B, and C must be same non-zero structure
*/ "
for prec in double float; do
  echo "void ${func[$i]}(const tensor::tensor_CRS<$prec> &A, const tensor::tensor_CRS<$prec> &B, tensor::tensor_CRS<$prec> &C);"
done
echo "/**@}*/"
done

echo ""

## matrix-scalar max min
detail=(greatest smallest)
func=(max min)
for i in ${!detail[@]}; do
echo "
/**
 * \defgroup vml_scrs${func[$i]} monolish::vml::${func[$i]}
 * @brief Create a new tensor_CRS matrix with ${detail[$i]} elements of tensor_CRS matrix or scalar (C[0:nnz] = ${func[$i]}(A[0:nnz], alpha))
 * @{
 */
/**
 * @brief Create a new tensor_CRS matrix with ${detail[$i]} elements of tensor_CRS matrix or scalar (C[0:nnz] = ${func[$i]}(A[0:nnz], alpha))
 * @param A monolish tensor_CRS matrix (size M x N)
 * @param alpha scalar value
 * @param C monolish tensor_CRS matrix (size M x N)
 * @note
 * - # of computation: nnz
 * - Multi-threading: true
 * - GPU acceleration: true
 *    - # of data transfer: 0
 * @warning
 * A and C must be same non-zero structure
*/ "
for prec in double float; do
  echo "void ${func[$i]}(const tensor::tensor_CRS<$prec> &A, const $prec alpha, tensor::tensor_CRS<$prec> &C);"
done
echo "/**@}*/"
done

echo ""

## tensor_CRS matrix max min
detail=(greatest smallest)
func=(max min)
for i in ${!detail[@]}; do
echo "
/**
 * \defgroup vml_crs${func[$i]} monolish::vml::${func[$i]}
 * @brief Finds the ${detail[$i]} element in tensor_CRS matrix (${func[$i]}(C[0:nnz]))
 * @{
 */
/**
 * @brief Finds the ${detail[$i]} element in tensor_CRS matrix (${func[$i]}(C[0:nnz]))
 * @param C monolish tensor_CRS matrix (size M x N)
 * @return ${detail[$i]} value
 * @note
 * - # of computation: nnz
 * - Multi-threading: true
 * - GPU acceleration: true
 * @warning
 * A, B, and C must be same non-zero structure
*/ "
for prec in double float; do
    echo "[[nodiscard]] $prec ${func[$i]}(const tensor::tensor_CRS<$prec> &C);"
done
echo "/**@}*/"
done

echo ""
#############################################

## tensor_CRS matrix alo
echo "
/**
* \defgroup vml_scrsalo monolish::vml::alo
 * @brief Asymmetric linear operation to tensor_CRS matrix elements (C[0:nnz] = alpha max(A[0:nnz], 0) + beta min(A[0:nnz], 0))
 * @{
 */
/**
 * @brief Asymmetric linear operation to tensor_CRS matrix elements (C[0:nnz] = alpha max(A[0:nnz], 0) + beta min(A[0:nnz], 0))
 * @param A monolish tensor_CRS matrix (size M x N)
 * @param alpha linear coefficient in positive range
 * @param beta linear coefficient in negative range
 * @param C monolish tensor_CRS matrix (size M x N)
 * @note
 * - # of computation: M*N
 * - Multi-threading: true
 * - GPU acceleration: true
*/ "
for prec in double float; do
  echo "void alo(const tensor::tensor_CRS<$prec> &A, const $prec alpha, const $prec beta, tensor::tensor_CRS<$prec> &C);"
done
echo "/**@}*/"

echo ""
#############################################

## reciprocal
echo "
/**
 * \defgroup vml_crsreciprocal monolish::vml::reciprocal
 * @brief reciprocal to tensor_CRS matrix elements (C[0:nnz] = 1 / A[0:nnz])
 * @{
 */
/**
 * @brief reciprocal to tensor_CRS matrix elements (C[0:nnz] = 1 / A[0:nnz])
 * @param A monolish tensor_CRS matrix (size M x N)
 * @param C monolish tensor_CRS matrix (size M x N)
 * @note
 * - # of computation: nnz
 * - Multi-threading: true
 * - GPU acceleration: true
 * @warning
 * A, B, and C must be same non-zero structure
*/ "
for prec in double float; do
  echo "void reciprocal(const tensor::tensor_CRS<$prec> &A, tensor::tensor_CRS<$prec> &C);"
done
echo "/**@}*/"

echo "}"
echo "}"
